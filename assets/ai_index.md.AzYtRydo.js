import{_ as i,c as a,o as e,ag as r}from"./chunks/framework.DK1-H3E1.js";const p=JSON.parse('{"title":"大语言模型 (LLM) 探索","description":"","frontmatter":{"order":1},"headers":[],"relativePath":"ai/index.md","filePath":"ai/index.md","lastUpdated":1770819148000}'),t={name:"ai/index.md"};function o(n,l,s,u,h,g){return e(),a("div",null,l[0]||(l[0]=[r('<h1 id="大语言模型-llm-探索" tabindex="-1">大语言模型 (LLM) 探索 <a class="header-anchor" href="#大语言模型-llm-探索" aria-label="Permalink to &quot;大语言模型 (LLM) 探索&quot;">​</a></h1><p>欢迎来到大语言模型技术探索专区！这里将深入探讨大语言模型的核心原理、实践应用和前沿技术。</p><h2 id="📚-内容概览" tabindex="-1">📚 内容概览 <a class="header-anchor" href="#📚-内容概览" aria-label="Permalink to &quot;📚 内容概览&quot;">​</a></h2><p>本模块专注于大语言模型 (Large Language Model, LLM) 相关的技术内容，涵盖从基础理论到实际应用的完整知识体系。</p><h2 id="🧠-核心主题" tabindex="-1">🧠 核心主题 <a class="header-anchor" href="#🧠-核心主题" aria-label="Permalink to &quot;🧠 核心主题&quot;">​</a></h2><h3 id="基础理论" tabindex="-1">基础理论 <a class="header-anchor" href="#基础理论" aria-label="Permalink to &quot;基础理论&quot;">​</a></h3><ul><li><p><strong>Transformer 架构</strong></p><ul><li>注意力机制 (Attention Mechanism)</li><li>位置编码 (Positional Encoding)</li><li>编码器-解码器结构</li><li>自注意力与交叉</li></ul></li><li><p><strong>预训练与微调</strong></p><ul><li>预训练目标函数</li><li>监督微调 (SFT)</li><li>强化学习人类反馈 (RLHF)</li><li>参数高效微调 (LoRA, P-Tuning 等)</li></ul></li><li><p><strong>模型架构演进</strong></p><ul><li>GPT 系列模型</li><li>BERT 系列模型</li><li>T5 与编码器-解码器架构</li><li>最新架构创新</li></ul></li></ul><h3 id="实践应用" tabindex="-1">实践应用 <a class="header-anchor" href="#实践应用" aria-label="Permalink to &quot;实践应用&quot;">​</a></h3><ul><li><p><strong>模型训练</strong></p><ul><li>数据准备与清洗</li><li>训练策略与技巧</li><li>分布式训练</li><li>模型评估与验证</li></ul></li><li><p><strong>模型部署</strong></p><ul><li>模型量化与压缩</li><li>推理优化</li><li>服务化部署</li><li>性能监控</li></ul></li><li><p><strong>应用开发</strong></p><ul><li><a href="/ai/prompt-engineering.html">Prompt 工程</a></li><li>RAG (检索增强生成)</li><li><a href="/ai/vector-embedding.html">向量嵌入 (Vector Embedding)</a></li><li>Agent 开发</li><li><a href="/ai/living-files-theory.html">活文件理论 (Living Files)</a></li><li><a href="/ai/openclaw-memory-architecture.html">OpenClaw 记忆系统架构</a></li><li>多模态应用</li></ul></li></ul><h3 id="前沿技术" tabindex="-1">前沿技术 <a class="header-anchor" href="#前沿技术" aria-label="Permalink to &quot;前沿技术&quot;">​</a></h3><ul><li><p><strong>模型能力</strong></p><ul><li>上下文理解与长文本处理</li><li>思维链推理 (Chain-of-Thought)</li><li>工具使用 (Tool Use)</li><li>多模态能力</li></ul></li><li><p><strong>优化技术</strong></p><ul><li>模型压缩与加速</li><li>知识蒸馏</li><li>模型剪枝</li><li>量化技术</li></ul></li><li><p><strong>安全与对齐</strong></p><ul><li>模型安全性</li><li>对齐技术</li><li>偏见与公平性</li><li>可解释性</li></ul></li></ul><h3 id="工具与框架" tabindex="-1">工具与框架 <a class="header-anchor" href="#工具与框架" aria-label="Permalink to &quot;工具与框架&quot;">​</a></h3><ul><li><p><strong>开发框架</strong></p><ul><li>Hugging Face Transformers</li><li>LangChain / LangGraph</li><li>LlamaIndex</li><li>vLLM / TensorRT-LLM</li></ul></li><li><p><strong>训练框架</strong></p><ul><li>DeepSpeed</li><li>FSDP (Fully Sharded Data Parallel)</li><li>Megatron-LM</li><li>Colossal-AI</li></ul></li><li><p><strong>部署工具</strong></p><ul><li>Ollama</li><li>Text Generation Inference (TGI)</li><li>TensorRT</li><li>ONNX Runtime</li></ul></li></ul><h2 id="🎯-学习路径" tabindex="-1">🎯 学习路径 <a class="header-anchor" href="#🎯-学习路径" aria-label="Permalink to &quot;🎯 学习路径&quot;">​</a></h2><ol><li><strong>入门阶段</strong>：理解 Transformer 架构和基础概念</li><li><strong>进阶阶段</strong>：掌握模型训练、微调和优化技术</li><li><strong>实践阶段</strong>：开发实际应用，解决具体问题</li><li><strong>深入阶段</strong>：研究前沿技术和架构创新</li></ol><hr><blockquote><p>💡 持续更新中，让我们一起探索大语言模型的无限可能！</p></blockquote>',17)]))}const c=i(t,[["render",o]]);export{p as __pageData,c as default};
